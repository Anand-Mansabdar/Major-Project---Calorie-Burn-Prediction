{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d4b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8978ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to standardize columns at beginning - includes trim, normalize spaces, snake-case, lowercase etc...\n",
    "def standardize_columns(df):\n",
    "  cols = []\n",
    "  for c in df.columns:\n",
    "    c2 = str(c).strip()  # Removes leading and trailing spaces\n",
    "    c2 = \" \".join(c2.split())\n",
    "    c2 = c2.replace(\" \", \"_\")\n",
    "    c2 = c2.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    c2 = c2.replace(\"/\", \"_per_\")\n",
    "    c2 = c2.lower()\n",
    "    cols.append(c2)  # Adds/appends the transformed column names into cols[]\n",
    "    \n",
    "  df.columns = cols\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e730513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify outliers in the data using IQR(InterQuartile Range)\n",
    "def cap_outliers_iqr(df, col, k=1.5):\n",
    "  if col not in df.columns:\n",
    "    return df\n",
    "  \n",
    "  x=df[col].dropna()\n",
    "  if len(x) < 10:\n",
    "    return df\n",
    "  \n",
    "  q1 = x.quantile(0.25)   # Setting range for 25%\n",
    "  q3 = x.quantile(0.75)   # Setting range for 75%\n",
    "  iqr = q3 - q1           # Picking IQR\n",
    "  \n",
    "  # Defining high and low values - Values less than low and greater than high are outliers. Hence we remove these values\n",
    "  low = q1 - k * iqr\n",
    "  high = q3 + k * iqr\n",
    "  \n",
    "  df[col] = df[col].clip(low, high)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a67e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a list of column names (usually from a DataFrame) and:\n",
    "# Cleans invalid characters\n",
    "# Standardizes formatting\n",
    "# Ensures all column names are unique\n",
    "# Prevents empty or broken names\n",
    "# This is commonly used before model training, feature engineering, or saving datasets.\n",
    "\n",
    "def clean_and_make_unique_feature_names(columns):\n",
    "  cleaned = []     # final list of cleaned column names\n",
    "  counts = {}      # tracks how many times a name appears (for uniqueness)\n",
    "  \n",
    "  for c in columns:\n",
    "    c = str(c)     # Convert column name to string\n",
    "    c = pd.Series([c]).str.replace(r\"[^A-Za-z0-9_]\", \"_\", regex=True).iloc[0]  # Replace invalid characters\n",
    "    c = pd.Series([c]).str.replace(r\"_+\", \"_\", regex=True).iloc[0]             # Collapse multiple underscores\n",
    "    c = c.strip(\"_\")                                                           # Remove underscores from both ends. Removes leading and trailing _\n",
    "    \n",
    "    if c == \"\":\n",
    "      c = \"feature\"                                                            # Handle empty names\n",
    "      \n",
    "    if c not in counts:                                                        # Ensure uniqueness\n",
    "      counts[c] = 1\n",
    "      cleaned.append(c)\n",
    "    else:\n",
    "      counts[c] += 1\n",
    "      cleaned.append(f\"{c}__{counts[c]}\")\n",
    "  return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d687ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It estimates a prediction interval for a regression model using bootstrap resampling of residuals.\n",
    "\n",
    "def bootstrap_prediction_interval(\n",
    "    model,\n",
    "    X_train,          # training features used to compute residuals\n",
    "    y_train,          # true training targets\n",
    "    X_new,            # new data point for prediction\n",
    "    n_boot=200,       # number of bootstrap simulations\n",
    "    alpha=0.10,       # significance level (10% → 90% interval)\n",
    "    random_state=42\n",
    "):\n",
    "    # Random generator for reproducibility (It makes random operations give the same result every time you run the code.)\n",
    "    rng = np.random.RandomState(random_state)\n",
    "\n",
    "    # Model predictions on training data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Residuals = actual - predicted\n",
    "    residuals = np.array(y_train) - np.array(y_train_pred)\n",
    "\n",
    "    # Point prediction for new input\n",
    "    y_new_pred = float(model.predict(X_new)[0])\n",
    "\n",
    "    simulated_predictions = []\n",
    "\n",
    "    # Bootstrap: add resampled residuals to new prediction\n",
    "    for _ in range(n_boot):\n",
    "      sampled_residual = rng.choice(residuals, size=1, replace=True)[0]\n",
    "      simulated_predictions.append(y_new_pred + sampled_residual)\n",
    "\n",
    "    # Lower and upper bounds of prediction interval (Lower and upper bounds quantify the uncertainty of a prediction — they tell us the range in which the true value is likely to lie.)\n",
    "    lower_bound = np.percentile(simulated_predictions, 100 * (alpha / 2))\n",
    "    upper_bound = np.percentile(simulated_predictions, 100 * (1 - alpha / 2))\n",
    "\n",
    "    # Return point prediction and prediction interval\n",
    "    return y_new_pred, lower_bound, upper_bound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a95d5",
   "metadata": {},
   "source": [
    "#### LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "806d86fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (20000, 54)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"workout_data.csv\")\n",
    "print(\"Original shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adcc7468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After columns standardization:  (20000, 54)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the columns\n",
    "df = standardize_columns(df=df)\n",
    "print(\"After columns standardization: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea836e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (top 15):\n",
      "age                                0\n",
      "gender                             0\n",
      "weight_kg                          0\n",
      "height_m                           0\n",
      "max_bpm                            0\n",
      "avg_bpm                            0\n",
      "resting_bpm                        0\n",
      "session_duration_hours             0\n",
      "calories_burned                    0\n",
      "workout_type                       0\n",
      "fat_percentage                     0\n",
      "water_intake_liters                0\n",
      "workout_frequency_days_per_week    0\n",
      "experience_level                   0\n",
      "bmi                                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Basic quality checks\n",
    "print(\"Missing values (top 15):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68588ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows:  0\n"
     ]
    }
   ],
   "source": [
    "# To check for duplicates and if present then remove them from the dataframe\n",
    "\n",
    "duplicates = df.duplicated().sum()\n",
    "print(\"Duplicate rows: \", duplicates)\n",
    "\n",
    "if duplicates > 0:\n",
    "  df = df.drop_duplicates().reset_index(drop=True)\n",
    "  print(f\"After dropping duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b31df698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height sanity check (1.4–2.1 m): bad_rows = 0\n",
      "Duration sanity check (0.25–2 hours): bad_rows = 8\n"
     ]
    }
   ],
   "source": [
    "# Type validation + unit checks\n",
    "# Convert object columns to numeric when most values are numeric\n",
    "for column_name in df.columns:\n",
    "    # Process only object (string/mixed-type) columns\n",
    "    if df[column_name].dtype == \"object\":\n",
    "\n",
    "        # Try converting values to numeric; invalid values become NaN\n",
    "        numeric_version = pd.to_numeric(df[column_name], errors=\"coerce\")\n",
    "        \n",
    "        # Check if at least 80% of values are valid numbers\n",
    "        if numeric_version.notna().mean() >= 0.80:\n",
    "            \n",
    "            # Replace original column with numeric version\n",
    "            df[column_name] = numeric_version\n",
    "\n",
    "# Sanity check for human height (in meters)\n",
    "if \"height_m\" in df.columns:\n",
    "\n",
    "    # Count rows with unrealistic height values\n",
    "    invalid_height_count = (\n",
    "        (df[\"height_m\"] < 1.4) | (df[\"height_m\"] > 2.1)\n",
    "    ).sum()\n",
    "    \n",
    "    print(\n",
    "        \"Height sanity check (1.4–2.1 m): bad_rows =\",\n",
    "        int(invalid_height_count)\n",
    "    )\n",
    "\n",
    "\n",
    "# Sanity check for workout/session duration (in hours)\n",
    "if \"session_duration_hours\" in df.columns:\n",
    "    \n",
    "    # Count sessions that are too short or too long\n",
    "    invalid_duration_count = (\n",
    "        (df[\"session_duration_hours\"] < 0.25) |\n",
    "        (df[\"session_duration_hours\"] > 2.0)\n",
    "    ).sum()\n",
    "    \n",
    "    print(\n",
    "        \"Duration sanity check (0.25–2 hours): bad_rows =\",\n",
    "        int(invalid_duration_count)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
